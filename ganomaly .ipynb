{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_fOFzTCbXTfi",
    "outputId": "4e0db446-6657-442e-a7e5-f81c198d1dee"
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from matplotlib import pyplot as plt\n",
    "from pylab import rcParams\n",
    "from keras.layers import Activation, Dense,Dot,merge, Dropout,Lambda,Permute,Multiply,LSTM, Conv2D, Flatten, MaxPooling2D, LSTM,RepeatVector,Reshape,TimeDistributed,UpSampling1D\n",
    "# import common as com\n",
    "import keras.models\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "# from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab_type": "text",
    "id": "jAzGntqyX583"
   },
   "outputs": [],
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lj9m8quMYrtB"
   },
   "outputs": [],
   "source": [
    "width = 128\n",
    "height = 64\n",
    "channels = 1\n",
    "input_dim = 640\n",
    "timesteps = 10\n",
    "n_features = 64\n",
    "lr = 0.001\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "numpyA = np.ones([1,64])\n",
    "\n",
    "def multA(x):\n",
    "    A = K.variable(np.ones([1,64]))\n",
    "\n",
    "    return K.dot(x,A)\n",
    "# def multa(x)\n",
    "def multA_T(x):\n",
    "    A = K.variable(np.ones([1,10]))\n",
    "\n",
    "    return K.dot(x,A)\n",
    "# weight_2 = Lambda(lambda x:x*0.2)\n",
    "# weight_gru1 = weight_2(gru1)\n",
    "# output = Lambda(lambda x: K.sum(x, axis=-1))(vec)\n",
    "# model.add(Lambda(multA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------#\n",
    "#   注意力模块\n",
    "#-------------------------------------------#\n",
    "def attention_3d_block(inputs):\n",
    "    # inputs.shape = (batch_size, time_steps, lstm_units)\n",
    "\n",
    "    # (batch_size, time_steps, lstm_units) -> (batch_size, lstm_units, time_steps)\n",
    "    a = Permute((2, 1))(inputs)\n",
    "\n",
    "    # 对最后一维进行全连接\n",
    "    # (batch_size, lstm_units, time_steps) -> (batch_size, lstm_units, time_steps)\n",
    "    a = Dense(10, activation='softmax')(a)\n",
    "\n",
    "    # (batch_size, lstm_units, time_steps) -> (batch_size, time_steps, lstm_units)\n",
    "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
    "\n",
    "    # 相乘\n",
    "    # 相当于获得每一个step中，每个维度在所有step中的权重\n",
    "    output_attention_mul = Multiply()([inputs,a_probs])\n",
    "#     output_attention_mul = merge([inputs, a_probs], name='attention_mul', mode='mul')\n",
    "    return output_attention_mul\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9V6k5E4HX8ns"
   },
   "source": [
    "## Generators Encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "colab_type": "code",
    "id": "6SSgbWtgYFge",
    "outputId": "ffb3b7cc-871f-4ef6-b1cb-6f2eb6193249",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 10, 64)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 10, 64)       4160        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10, 64)       0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 10)           0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 10, 1)        0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 10, 64)       0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 64)       0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 10, 64)       0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 10, 64)       0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 10, 64)       0           lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 640)          0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          328192      reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512)          2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 256)          131328      activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          65792       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256)          0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          32896       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128)          0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          16512       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128)          512         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            1032        activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 8)            32          dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 8)            0           batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 585,064\n",
      "Trainable params: 582,488\n",
      "Non-trainable params: 2,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "input_layer = Input(name='input', shape=(input_dim, ))\n",
    "\n",
    "input_layer1 = Reshape((timesteps,64))(input_layer)#[10,64]\n",
    "att = TimeDistributed(Dense(64))(input_layer1)#[B,T,F]\n",
    "att = Activation('sigmoid')(att)\n",
    "\n",
    "att1 = Lambda(lambda x: K.sum(x, axis=-1))(att)\n",
    "att1 = Reshape([-1,1])(att1)\n",
    "att1 = Lambda(multA)(att1)\n",
    "att1 = Reshape([-1,64])(att1)\n",
    "\n",
    "att = Lambda(lambda x:x*64)(att)\n",
    "att1 = Lambda(lambda x:1/x)(att1)\n",
    "freq_fnorm = Multiply()([att,att1])\n",
    "\n",
    "h = Reshape((640,))(freq_fnorm)\n",
    "# h= Flatten()(cnn_input)\n",
    "# print(h.shape)\n",
    "h = Dense(512)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(128)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(128)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "h = Dense(8)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "  \n",
    "g_e = keras.models.Model(inputs=input_layer, outputs=h)\n",
    "\n",
    "\n",
    "g_e.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CsFGE97WYMts"
   },
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "colab_type": "code",
    "id": "pivNg2CMYQwi",
    "outputId": "4281bfb2-df6d-4958-b3e5-dd75d06f866a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 8)                 585064    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 128)               1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 640)               328320    \n",
      "=================================================================\n",
      "Total params: 1,166,568\n",
      "Trainable params: 1,161,432\n",
      "Non-trainable params: 5,136\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim,))\n",
    "\n",
    "x = g_e(input_layer)\n",
    "\n",
    "\n",
    "y = Dense(128)(x)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(128)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(256)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(256)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(512)(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = Activation('relu')(y)\n",
    "\n",
    "y = Dense(input_dim)(y)\n",
    "\n",
    "\n",
    "g = keras.models.Model(inputs=input_layer, outputs=y)\n",
    "\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6xJahMZrZReX"
   },
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "coa6bXCRYRG9",
    "outputId": "9554afeb-f0a2-45ad-82d0-44c0f245be5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 10, 64)       0           input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 10, 64)       4160        reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 10, 64)       0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 10)           0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 10, 1)        0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 10, 64)       0           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 10, 64)       0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 10, 64)       0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 10, 64)       0           reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, 10, 64)       0           lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 10, 64)       0           reshape_5[0][0]                  \n",
      "                                                                 multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 640)          0           multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 512)          328192      reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 512)          2048        dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 512)          0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 256)          131328      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 256)          1024        dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 256)          0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 256)          65792       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 256)          1024        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 256)          0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 128)          32896       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128)          512         dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 128)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 128)          16512       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128)          512         dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 128)          0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 8)            1032        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 8)            32          dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8)            0           batch_normalization_17[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 585,064\n",
      "Trainable params: 582,488\n",
      "Non-trainable params: 2,576\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_layer = Input(name='input', shape=(input_dim, ))\n",
    "\n",
    "input_layer1 = Reshape((timesteps,64))(input_layer)#[10,64]\n",
    "att = TimeDistributed(Dense(64))(input_layer1)#[B,T,F]\n",
    "att = Activation('sigmoid')(att)\n",
    "\n",
    "att1 = Lambda(lambda x: K.sum(x, axis=-1))(att)\n",
    "att1 = Reshape([-1,1])(att1)\n",
    "att1 = Lambda(multA)(att1)\n",
    "att1 = Reshape([-1,64])(att1)\n",
    "\n",
    "att = Lambda(lambda x:x*64)(att)\n",
    "att1 = Lambda(lambda x:1/x)(att1)\n",
    "freq_fnorm = Multiply()([att,att1])\n",
    "cnn_input = Multiply()([input_layer1,freq_fnorm])\n",
    "\n",
    "z = Reshape((640,))(cnn_input)\n",
    "\n",
    "z = Dense(512)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(256)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(256)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(128)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(128)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "z = Dense(8)(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = Activation('relu')(z)\n",
    "\n",
    "encoder = keras.models.Model(input_layer, z)\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WHU8SoiCZUCH"
   },
   "source": [
    "## feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 544
    },
    "colab_type": "code",
    "id": "tovsU-1uZXzr",
    "outputId": "b2fe7fe5-bf33-42e1-c5bd-dea57e33e762"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               328192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 513,024\n",
      "Trainable params: 510,976\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(name='input', shape=(input_dim,))\n",
    "\n",
    "f = Dense(512)(input_layer)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "h = Dense(256)(h)\n",
    "h = BatchNormalization()(h)\n",
    "h = Activation('relu')(h)\n",
    "\n",
    "f = Dense(256)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "f = Dense(128)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "f = Dense(128)(f)\n",
    "f = BatchNormalization()(f)\n",
    "f = Activation('relu')(f)\n",
    "\n",
    "feature_extractor = keras.models.Model(input_layer, f)\n",
    "\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z7HBx1GiZhm-"
   },
   "source": [
    "## gan trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "bosacIf7ZkZ4",
    "outputId": "341417b4-0771-466f-c9d0-68554e089f8e"
   },
   "outputs": [],
   "source": [
    "class AdvLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AdvLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori_feature = feature_extractor(x[0])\n",
    "        gan_feature = feature_extractor(x[1])\n",
    "        return K.mean(K.square(ori_feature - K.mean(gan_feature, axis=0)))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "class CntLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CntLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori = x[0]\n",
    "        gan = x[1]\n",
    "        return K.mean(K.square(ori - gan))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "class EncLoss(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(EncLoss, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        ori = x[0]\n",
    "        gan = x[1]\n",
    "        return K.mean(K.square(g_e(ori) - encoder(gan)))\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return (input_shape[0][0], 1)\n",
    "    \n",
    "# model for training\n",
    "input_layer = layers.Input(name='input', shape=(input_dim,))\n",
    "gan = g(input_layer) # g(x)\n",
    "\n",
    "adv_loss = AdvLoss(name='adv_loss')([input_layer, gan])\n",
    "cnt_loss = CntLoss(name='cnt_loss')([input_layer, gan])\n",
    "enc_loss = EncLoss(name='enc_loss')([input_layer, gan])\n",
    "\n",
    "gan_trainer = keras.models.Model(input_layer, [adv_loss, cnt_loss, enc_loss])\n",
    "\n",
    "# loss function\n",
    "def loss(yt, yp):\n",
    "    return yp\n",
    "\n",
    "losses = {\n",
    "    'adv_loss': loss,\n",
    "    'cnt_loss': loss,\n",
    "    'enc_loss': loss,\n",
    "}\n",
    "\n",
    "lossWeights = {'cnt_loss': 10.0, 'adv_loss': 1.0, 'enc_loss': 1.0}\n",
    "\n",
    "# compile\n",
    "gan_trainer.compile(optimizer=keras.optimizers.Adam(lr=lr), loss=losses, loss_weights=lossWeights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "6YlrDrqZUfJG",
    "outputId": "bee8ea69-6b60-45ed-e7d2-73596eb6d102"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 640)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Model)                 (None, 640)          1166568     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "adv_loss (AdvLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_2[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "cnt_loss (CntLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_2[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "enc_loss (EncLoss)              [(None, 640), (None, 0           input[0][0]                      \n",
      "                                                                 model_2[2][0]                    \n",
      "==================================================================================================\n",
      "Total params: 1,166,568\n",
      "Trainable params: 1,161,432\n",
      "Non-trainable params: 5,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan_trainer.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pWWVBPizZctk"
   },
   "source": [
    "## discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "xcJdjTerZbMN",
    "outputId": "837e9958-23db-408c-916e-2e0c23250d0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "model_4 (Model)              (None, 128)               513024    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                4128      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "d_out (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 517,313\n",
      "Trainable params: 515,201\n",
      "Non-trainable params: 2,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = layers.Input(name='input', shape=(input_dim,))\n",
    "\n",
    "f = feature_extractor(input_layer)\n",
    "\n",
    "d = Dense(32)(f)\n",
    "d = BatchNormalization()(d)\n",
    "d = Activation('elu')(d)\n",
    "\n",
    "d = layers.Dense(1, activation='sigmoid', name='d_out')(d)    \n",
    "\n",
    "d = keras.models.Model(input_layer, d)\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "W6d91GYncIGT",
    "outputId": "f7e33a25-4b54-46b8-c6c8-5362e00b9da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "d.compile(optimizer=keras.optimizers.Adam(lr=lr), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6f6m8x7bDUX"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oniqQC4ZbN06"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6018/6018 [00:34<00:00, 173.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1829472, 640)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# from keras.datasets import mnist\n",
    "# import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "# additional\n",
    "import numpy as np\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "import librosa.core\n",
    "import librosa.feature\n",
    "n_mels=64\n",
    "n_frames= 10\n",
    "n_hop_frames= 1\n",
    "n_fft= 1024\n",
    "hop_length= 512\n",
    "power= 2.0\n",
    "in_dir_c = '/root/DCASE2021/dev_data/pump/train/'\n",
    "wav_list_c = os.listdir(in_dir_c)\n",
    "idx = 0\n",
    "\n",
    "for  wav_file_c in tqdm(wav_list_c):     \n",
    "    if wav_file_c.endswith('.wav'):\n",
    "        indir_c1 = in_dir_c + wav_file_c\n",
    "        dims = n_mels * n_frames\n",
    "        y, sr = librosa.load(indir_c1, sr=None, mono=True)\n",
    "#         y -= np.mean(y)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y,\n",
    "                                                     sr=sr,\n",
    "                                                     n_fft=n_fft,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     power=power)\n",
    "        log_mel_spectrogram = 20.0 / power * np.log10(np.maximum(mel_spectrogram, sys.float_info.epsilon))#(128, 313)\n",
    "#         log_mel_spectrogram = np.abs(log_mel_spectrogram)\n",
    "#         log_mel_spectrogram = np.mean(log_mel_spectrogram, axis=-1)\n",
    "        \n",
    "        n_vectors = len(log_mel_spectrogram[0, :]) - n_frames + 1\n",
    "#         print(n_vectors)\n",
    "        if n_vectors < 1:\n",
    "            vectors = np.empty((0, dims))\n",
    "        vectors = np.zeros((n_vectors, dims))#(250, 8192)\n",
    "        for t in range(n_frames):\n",
    "            vectors[:, n_mels * t : n_mels * (t + 1)] = log_mel_spectrogram[:, t : t + n_vectors].T\n",
    "        vectors = vectors[: : n_hop_frames, :]\n",
    "        if idx == 0:\n",
    "            data = np.zeros((len(wav_list_c) * vectors.shape[0], dims), float)\n",
    "        data[vectors.shape[0] * idx : vectors.shape[0] * (idx + 1), :] = vectors#(752250, 8192)\n",
    "        idx = 1+idx\n",
    "        \n",
    "        #print(data[0].shape)\n",
    "#x_ok = data.reshape(data.shape[0], 64, 128, 1)#[data.shape[0],64,128,1]\n",
    "x_ok = data\n",
    "print(x_ok.shape)\n",
    "\n",
    "image = np.reshape(x_ok[i:i+1], (64, 128))\n",
    "# image = image * 127 + 127\n",
    "plt.imshow(image)  \n",
    "\n",
    "\n",
    "\n",
    "in_dir_c1 = '/root/DCASE2021/dev_data/valve/source_test/'\n",
    "wav_list_c1 = os.listdir(in_dir_c1)\n",
    "y_test = []\n",
    "idx = 0\n",
    "for wav_file_c in tqdm(wav_list_c1):    \n",
    "    if wav_file_c.endswith('.wav'):\n",
    "#         print(wav_file_c.split('_')[4])\n",
    "        if wav_file_c.split('_')[4] == 'anomaly':\n",
    "            for i in range(309):\n",
    "                y_test.append(0)\n",
    "        else :\n",
    "            for i in range(309):\n",
    "                y_test.append(1)\n",
    "        indir_c1 = in_dir_c1 + wav_file_c\n",
    "        dims = n_mels * n_frames\n",
    "        y, sr = librosa.load(indir_c1, sr=None, mono=True)\n",
    "        mel_spectrogram = librosa.feature.melspectrogram(y=y,\n",
    "                                                     sr=sr,\n",
    "                                                     n_fft=n_fft,\n",
    "                                                     hop_length=hop_length,\n",
    "                                                     n_mels=n_mels,\n",
    "                                                     power=power)\n",
    "        log_mel_spectrogram = 20.0 / power * np.log10(np.maximum(mel_spectrogram, sys.float_info.epsilon))#(128, 313)\n",
    "        n_vectors1 = len(log_mel_spectrogram[0, :]) - n_frames + 1\n",
    "        \n",
    "#         if n_vectors1 < 1:\n",
    "#             vectors1 = np.empty((0, dims))\n",
    "        vectors1 = np.zeros((n_vectors1, dims))#(250, 8192)\n",
    "        for t in range(n_frames):\n",
    "            vectors1[:, n_mels * t : n_mels * (t + 1)] = log_mel_spectrogram[:, t : t + n_vectors1].T\n",
    "        vectors1 = vectors1[: : n_hop_frames, :]\n",
    "        #print(vectors1.shape)\n",
    "        if idx == 0:\n",
    "            data1 = np.zeros((len(wav_list_c1) * vectors1.shape[0], dims), float)\n",
    "        \n",
    "        data1[vectors1.shape[0] * idx : vectors1.shape[0] * (idx + 1), :] = vectors1#(752250, 8192)\n",
    "        idx = 1+idx\n",
    "        \n",
    "x_test = data1.reshape(data1.shape[0], 64, 128, 1)#[data.shape[0],64,128,1]\n",
    "x_test = data1\n",
    "x_ok.max()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dxPzCEC1bFMR"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDYFHg6Iboh4"
   },
   "outputs": [],
   "source": [
    "niter = 20000\n",
    "bz = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53rLCTe3a8LY"
   },
   "outputs": [],
   "source": [
    "def get_data_generator(data, batch_size=32):\n",
    "    datalen = len(data)\n",
    "    cnt = 0\n",
    "    while True:\n",
    "        idxes = np.arange(datalen)\n",
    "        np.random.shuffle(idxes)\n",
    "        cnt += 1\n",
    "        for i in range(int(np.ceil(datalen/batch_size))):\n",
    "            train_x = np.take(data, idxes[i*batch_size: (i+1) * batch_size], axis=0)\n",
    "            y = np.ones(len(train_x))\n",
    "            yield train_x, [y, y, y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fHQxiAHia_5J"
   },
   "outputs": [],
   "source": [
    "train_data_generator = get_data_generator(x_ok, bz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 698
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "OKkjwML7bjqg",
    "outputId": "5e1c9f56-b705-49b8-8825-69686eac039d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004782969\n",
      "6.988934 6.988934\n",
      "niter: 1, g_loss: [70.4838, 0.3914475, 6.988934, 0.20300852], d_loss: 0.02509298548102379\n",
      "6.821381 6.821381\n",
      "niter: 101, g_loss: [68.79824, 0.3913836, 6.821381, 0.1930431], d_loss: 0.00910855457186699\n",
      "niter: 201, g_loss: [69.45964, 0.3913914, 6.887008, 0.19817664], d_loss: 0.018827510997653008\n",
      "niter: 301, g_loss: [71.02338, 0.38675678, 7.0421133, 0.21548603], d_loss: 0.008351164869964123\n",
      "6.492843 6.492843\n",
      "niter: 401, g_loss: [65.507645, 0.38961262, 6.492843, 0.18960677], d_loss: 0.00949561595916748\n",
      "niter: 501, g_loss: [69.99956, 0.37988013, 6.9411664, 0.20801005], d_loss: 0.004994094371795654\n",
      "niter: 601, g_loss: [66.53683, 0.37857887, 6.5945406, 0.21284321], d_loss: 0.00425156531855464\n",
      "niter: 701, g_loss: [66.73599, 0.38837907, 6.614589, 0.20171762], d_loss: 0.02233564481139183\n",
      "niter: 801, g_loss: [67.80025, 0.37234056, 6.7228427, 0.19948912], d_loss: 0.0197482630610466\n",
      "niter: 901, g_loss: [66.17634, 0.37281024, 6.561015, 0.19337545], d_loss: 0.011563918553292751\n",
      "0.00043046721\n",
      "niter: 1001, g_loss: [65.658455, 0.37678277, 6.5081825, 0.19984412], d_loss: 0.00080005859490484\n",
      "niter: 1101, g_loss: [65.84852, 0.37724754, 6.5264883, 0.20638502], d_loss: 0.0034688194282352924\n",
      "6.3562202 6.3562202\n",
      "niter: 1201, g_loss: [64.13699, 0.37161684, 6.3562202, 0.20317508], d_loss: 0.0025786543264985085\n",
      "niter: 1301, g_loss: [64.62173, 0.37058422, 6.4051065, 0.20008278], d_loss: 0.0010602357797324657\n",
      "6.3186436 6.3186436\n",
      "niter: 1401, g_loss: [63.77774, 0.37478626, 6.3186436, 0.21651995], d_loss: 0.014273508451879025\n",
      "niter: 1501, g_loss: [65.20441, 0.36980397, 6.4634314, 0.20028973], d_loss: 0.0024750472512096167\n",
      "niter: 1601, g_loss: [64.53705, 0.3673786, 6.3963003, 0.2066667], d_loss: 0.0037262258119881153\n",
      "6.2723927 6.2723927\n",
      "niter: 1701, g_loss: [63.290157, 0.36883613, 6.2723927, 0.19739717], d_loss: 0.004540049470961094\n",
      "6.1921587 6.1921587\n",
      "niter: 1801, g_loss: [62.50122, 0.36956257, 6.1921587, 0.21007106], d_loss: 0.00331117189489305\n",
      "niter: 1901, g_loss: [63.034813, 0.37305427, 6.245232, 0.20943737], d_loss: 0.0005887369625270367\n",
      "0.000387420489\n",
      "niter: 2001, g_loss: [62.996872, 0.37118867, 6.243317, 0.19251226], d_loss: 0.011812770739197731\n",
      "niter: 2101, g_loss: [62.547054, 0.37839192, 6.1964803, 0.20385979], d_loss: 0.01160441618412733\n",
      "6.137391 6.137391\n",
      "niter: 2201, g_loss: [61.945793, 0.37480187, 6.137391, 0.19708179], d_loss: 0.0032069855369627476\n",
      "6.1240954 6.1240954\n",
      "niter: 2301, g_loss: [61.809666, 0.37637424, 6.1240954, 0.1923381], d_loss: 0.003561449935659766\n",
      "niter: 2401, g_loss: [62.578773, 0.36764547, 6.2000623, 0.21050607], d_loss: 0.003326255828142166\n",
      "niter: 2501, g_loss: [62.41778, 0.36612773, 6.184624, 0.20541272], d_loss: 0.01790039800107479\n",
      "niter: 2601, g_loss: [62.225117, 0.36685574, 6.1666837, 0.19142391], d_loss: 0.018745753914117813\n",
      "niter: 2701, g_loss: [61.845657, 0.36865616, 6.1279683, 0.19732083], d_loss: 0.012222846038639545\n",
      "niter: 2801, g_loss: [62.50308, 0.36710584, 6.1935163, 0.20080902], d_loss: 0.004165831487625837\n",
      "6.1128545 6.1128545\n",
      "niter: 2901, g_loss: [61.69599, 0.36029392, 6.1128545, 0.20715521], d_loss: 0.0007717257249169052\n",
      "0.0003486784401\n",
      "5.95761 5.95761\n",
      "niter: 3001, g_loss: [60.144287, 0.37063432, 5.95761, 0.19754642], d_loss: 0.0012950038071721792\n",
      "niter: 3101, g_loss: [61.917034, 0.36998874, 6.133678, 0.21026717], d_loss: 0.012979786843061447\n",
      "niter: 3201, g_loss: [60.957314, 0.3637467, 6.0394435, 0.19913161], d_loss: 0.0024571206886321306\n",
      "5.957412 5.957412\n",
      "niter: 3301, g_loss: [60.129295, 0.36273772, 5.957412, 0.19243515], d_loss: 0.004268229007720947\n",
      "niter: 3401, g_loss: [60.50102, 0.35659432, 5.995197, 0.1924571], d_loss: 0.025349251925945282\n",
      "niter: 3501, g_loss: [60.134815, 0.358948, 5.957474, 0.20112778], d_loss: 0.005720488261431456\n",
      "niter: 3601, g_loss: [62.511646, 0.3571928, 6.19595, 0.19495367], d_loss: 0.010179318487644196\n",
      "niter: 3701, g_loss: [62.20907, 0.35489362, 6.1649637, 0.20454076], d_loss: 0.0017073029885068536\n",
      "niter: 3801, g_loss: [60.96746, 0.35580444, 6.041569, 0.1959642], d_loss: 0.0004405708459671587\n",
      "niter: 3901, g_loss: [60.268764, 0.35270426, 5.971599, 0.20006882], d_loss: 0.006174386478960514\n",
      "0.00031381059609000004\n",
      "niter: 4001, g_loss: [61.27191, 0.3425681, 6.074027, 0.18907247], d_loss: 0.0005475030047819018\n",
      "5.8935895 5.8935895\n",
      "niter: 4101, g_loss: [59.48736, 0.35187748, 5.8935895, 0.19958375], d_loss: 0.0013587807770818472\n",
      "niter: 4201, g_loss: [60.44877, 0.35705855, 5.989041, 0.20130242], d_loss: 0.0034735884983092546\n",
      "niter: 4301, g_loss: [60.46639, 0.34862494, 5.990798, 0.20978166], d_loss: 0.0002505980955902487\n",
      "niter: 4401, g_loss: [60.69962, 0.35536388, 6.014944, 0.19481109], d_loss: 0.009560097940266132\n",
      "niter: 4501, g_loss: [61.49413, 0.34845018, 6.0948186, 0.19749302], d_loss: 0.0010377427097409964\n",
      "niter: 4601, g_loss: [59.651066, 0.35371348, 5.911258, 0.1847668], d_loss: 0.004093695431947708\n",
      "niter: 4701, g_loss: [60.84102, 0.34876868, 6.0298004, 0.19424345], d_loss: 0.007328202947974205\n",
      "niter: 4801, g_loss: [59.713894, 0.3471491, 5.9148855, 0.21788965], d_loss: 0.0009437805856578052\n",
      "niter: 4901, g_loss: [59.7789, 0.34557527, 5.9229093, 0.20423365], d_loss: 0.0027621721383184195\n",
      "0.00028242953648100003\n",
      "niter: 5001, g_loss: [59.573856, 0.35070908, 5.902805, 0.19510017], d_loss: 0.00014591170474886894\n",
      "niter: 5101, g_loss: [61.200863, 0.3377786, 6.066992, 0.193166], d_loss: 0.004056441131979227\n",
      "niter: 5201, g_loss: [60.09736, 0.34571248, 5.955104, 0.2006059], d_loss: 0.0002770048740785569\n",
      "niter: 5301, g_loss: [60.83544, 0.34026954, 6.028149, 0.21367928], d_loss: 0.004481342621147633\n",
      "niter: 5401, g_loss: [60.0211, 0.33449316, 5.9486485, 0.20012389], d_loss: 0.0005541006685234606\n",
      "5.796403 5.796403\n",
      "niter: 5501, g_loss: [58.504955, 0.3433101, 5.796403, 0.19761477], d_loss: 0.012353694066405296\n",
      "niter: 5601, g_loss: [58.70142, 0.33421323, 5.8180013, 0.18719567], d_loss: 0.0027197760064154863\n",
      "niter: 5701, g_loss: [60.43798, 0.32978034, 5.99174, 0.19079542], d_loss: 0.0008110437192954123\n",
      "niter: 5801, g_loss: [64.78033, 0.34008977, 6.422467, 0.21557185], d_loss: 0.0010813656263053417\n",
      "niter: 5901, g_loss: [60.58106, 0.34770375, 6.0041804, 0.19155172], d_loss: 0.0019416424911469221\n",
      "0.00025418658283290005\n",
      "niter: 6001, g_loss: [60.804245, 0.33470634, 6.027053, 0.1990082], d_loss: 0.003932070918381214\n",
      "niter: 6101, g_loss: [59.349583, 0.33266667, 5.881667, 0.20024286], d_loss: 0.01972411572933197\n",
      "niter: 6201, g_loss: [60.34721, 0.32574022, 5.9836383, 0.18508708], d_loss: 0.0031845420598983765\n",
      "niter: 6301, g_loss: [58.91237, 0.33158147, 5.8391194, 0.18959321], d_loss: 0.000584179419092834\n",
      "niter: 6401, g_loss: [59.322437, 0.32842955, 5.8796315, 0.1976925], d_loss: 0.003319431096315384\n",
      "niter: 6501, g_loss: [59.77933, 0.3285221, 5.9250917, 0.19989266], d_loss: 0.003546884749084711\n",
      "niter: 6601, g_loss: [58.784573, 0.32854557, 5.8275995, 0.18003467], d_loss: 0.0001317377609666437\n",
      "niter: 6701, g_loss: [73.5986, 0.32488826, 7.3040934, 0.23278394], d_loss: 0.00039921796997077763\n",
      "niter: 6801, g_loss: [62.8868, 0.35972545, 6.2315893, 0.21117795], d_loss: 0.008559059351682663\n",
      "niter: 6901, g_loss: [60.96607, 0.35308954, 6.042809, 0.18489009], d_loss: 0.009096239693462849\n",
      "0.00022876792454961005\n",
      "niter: 7001, g_loss: [59.730618, 0.34326288, 5.9209547, 0.17780817], d_loss: 0.000624285894446075\n",
      "niter: 7101, g_loss: [60.001675, 0.33961326, 5.947018, 0.1918781], d_loss: 0.008226805366575718\n",
      "niter: 7201, g_loss: [60.720654, 0.33744, 6.0176473, 0.20674133], d_loss: 0.015033645555377007\n",
      "niter: 7301, g_loss: [60.417286, 0.34067094, 5.9886475, 0.19014035], d_loss: 0.0016901051858440042\n",
      "5.736484 5.736484\n",
      "niter: 7401, g_loss: [57.90876, 0.3498844, 5.736484, 0.1940359], d_loss: 0.0005175109836272895\n",
      "niter: 7501, g_loss: [59.06568, 0.34301952, 5.853467, 0.18799183], d_loss: 0.001278725452721119\n",
      "niter: 7601, g_loss: [60.36291, 0.34421718, 5.9818006, 0.20069231], d_loss: 0.0002956479729618877\n",
      "niter: 7701, g_loss: [60.123, 0.34488156, 5.958416, 0.19395822], d_loss: 0.005584794096648693\n",
      "5.718891 5.718891\n",
      "niter: 7801, g_loss: [57.72152, 0.3459248, 5.718891, 0.1866846], d_loss: 0.0016672441270202398\n",
      "niter: 7901, g_loss: [58.631195, 0.34842396, 5.8096457, 0.18631211], d_loss: 0.00031570903956890106\n",
      "0.00020589113209464906\n",
      "niter: 8001, g_loss: [59.79943, 0.34654215, 5.926198, 0.19091032], d_loss: 0.00126510055270046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "niter: 8101, g_loss: [59.235, 0.33401415, 5.871101, 0.1899743], d_loss: 0.0008263522759079933\n",
      "niter: 8201, g_loss: [59.852787, 0.34147722, 5.932124, 0.1900686], d_loss: 0.0014100061962381005\n",
      "niter: 8301, g_loss: [60.1232, 0.3455362, 5.9580297, 0.19736578], d_loss: 0.0018269075080752373\n",
      "niter: 8401, g_loss: [60.84433, 0.3422202, 6.0308676, 0.19343089], d_loss: 0.0002731106651481241\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-c9e048233df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mfake_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#     print(lr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0md_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_x\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1399\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1401\u001b[0;31m                                             callbacks=callbacks)\n\u001b[0m\u001b[1;32m   1402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1403\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'begin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "min = 10000\n",
    "for i in range(niter):\n",
    "    \n",
    "    \n",
    "    if i % 1000 == 0:\n",
    "        lr *= 0.9\n",
    "        print(lr)\n",
    "    # get batch x, y ###\n",
    "    x, y = train_data_generator.__next__()\n",
    "        \n",
    "    ### train disciminator ###\n",
    "    d.trainable = True\n",
    "        \n",
    "    fake_x = g.predict(x)\n",
    "#     print(lr)    \n",
    "    d_x = np.concatenate([x, fake_x], axis=0)\n",
    "    d_y = np.concatenate([np.zeros(len(x)), np.ones(len(fake_x))], axis=0)\n",
    "        \n",
    "    d_loss = d.train_on_batch(d_x, d_y)\n",
    "\n",
    "    ### train generator ###\n",
    "    \n",
    "    d.trainable = False        \n",
    "    g_loss = gan_trainer.train_on_batch(x, y)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        if(g_loss[2]<min):\n",
    "            min = g_loss[2]\n",
    "            #print(type(g_loss[2]))\n",
    "            print(g_loss[2],min)\n",
    "            g.save(\"model/model_pump.hdf5\")\n",
    "        print(f'niter: {i+1}, g_loss: {g_loss}, d_loss: {d_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gc\n",
    "########################################################################\n",
    "\n",
    "\n",
    "########################################################################\n",
    "# import additional libraries\n",
    "########################################################################\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "# from import\n",
    "from tqdm import tqdm\n",
    "try:\n",
    "    from sklearn.externals import joblib\n",
    "except:\n",
    "    import joblib\n",
    "# original lib\n",
    "# import common as com\n",
    "\n",
    "y_pred = []\n",
    "start_idx = 0\n",
    "n_vectors_ea_file = 304\n",
    "for file_idx in range(6018):\n",
    "    y_pred.append(np.mean(np.square(x_ok[start_idx : start_idx + n_vectors_ea_file, :] \n",
    "                                      - g.predict(x_ok[start_idx : start_idx + n_vectors_ea_file, :]))))\n",
    "    start_idx += n_vectors_ea_file\n",
    "\n",
    "shape_hat, loc_hat, scale_hat = scipy.stats.gamma.fit(y_pred)\n",
    "gamma_params = [shape_hat, loc_hat, scale_hat]\n",
    "joblib.dump(gamma_params, \"model/score_distr_ToyCar.pkl\")\n",
    "decision_threshold = scipy.stats.gamma.ppf(q=0.9, a=shape_hat, loc=loc_hat, scale=scale_hat)        \n",
    "print(decision_threshold)        \n",
    "g.save(\"model/model_ToyTrain.hdf5\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ganomaly",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
